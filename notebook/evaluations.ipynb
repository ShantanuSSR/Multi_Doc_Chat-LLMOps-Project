{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a27836a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccbb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# QA\n",
    "inputs = [\n",
    "    \"What is the Transformer model introduced in the paper 'Attention Is All You Need'?\",\n",
    "    \"Write the formula for Scaled Dot-Product Attention and briefly explain its components.\",\n",
    "    \"List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\",\n",
    "    \"What are the equations for positional encoding and why are they important in the Transformer?\",\n",
    "    \"Which optimizer and learning rate schedule were used in the Transformer model, and what value was chosen for warmup_steps?\"\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"The Transformer is a sequence-to-sequence model that relies entirely on attention mechanisms, removing recurrence and convolutions to improve parallelization and performance.\",\n",
    "    \"The formula is Attention(Q, K, V) = softmax(QK^T / sqrt(d_k))V, where Q are queries, K are keys, V are values, and d_k is the key dimension used for scaling.\",\n",
    "    \"Self-attention allows higher parallelization, has a shorter path between long-range dependencies, and provides lower computational complexity per layer compared to recurrent or convolutional models.\",\n",
    "    \"Positional encodings use sine and cosine functions: PE(pos, 2i) = sin(pos / 10000^(2i/d_model)) and PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model)); they inject token position information since the Transformer lacks recurrence or convolution.\",\n",
    "    \"The authors used the Adam optimizer with β1=0.9, β2=0.98, ε=1e-9, and a learning rate schedule defined as d_model^-0.5 * min(step_num^-0.5, step_num * warmup_steps^-1.5), with warmup_steps set to 4000.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Dataset\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Write to csv\n",
    "csv_path = \"/home/shantanusingh/Downloads/Multi_doc_chat_proj/data/llmops_dataset.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5984f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['435483ca-eb97-461f-be7c-d5a95af5151b',\n",
       "  '6eb5550e-3cf2-4901-9188-1c1e10ad34ea',\n",
       "  'de414544-554c-4b13-80b8-3f919ba40391',\n",
       "  '3f2100f1-8284-4127-84e2-28fdbcc3b7e3',\n",
       "  '1059bd82-4b2b-474e-95c6-9fe6da132bbd'],\n",
       " 'count': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"llmops_attention_paper_dataset\"\n",
    "\n",
    "# Store\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Input and expected output pairs for llmops_attention_paper_dataset\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7617b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/shantanusingh/Downloads/Multi_doc_chat_proj\")\n",
    "\n",
    "from pathlib import Path\n",
    "from multi_doc_chat.src.document_ingestion.data_ingestion import ChatIngestor\n",
    "from multi_doc_chat.src.document_chat.retrieval import ConversationalRAG\n",
    "import os\n",
    "\n",
    "# Simple file adapter for local file paths\n",
    "class LocalFileAdapter:\n",
    "    \"\"\"Adapter for local file paths to work with ChatIngestor.\"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        self.path = Path(file_path)\n",
    "        self.name = self.path.name\n",
    "    \n",
    "    def getbuffer(self) -> bytes:\n",
    "        return self.path.read_bytes()\n",
    "\n",
    "\n",
    "def answer_ai_report_question(\n",
    "    inputs: dict,\n",
    "    data_path: str = \"/home/shantanusingh/Downloads/Multi_doc_chat_proj/data/attention.pdf\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Answer questions about the Attention paper using RAG.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary containing the question, e.g., {\"question\": \"What is RAG?\"}\n",
    "        data_path: Path to the Attention paper pdf file\n",
    "        chunk_size: Size of text chunks for splitting\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the answer, e.g., {\"answer\": \"RAG stands for...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract question from inputs\n",
    "        question = inputs.get(\"question\", \"\")\n",
    "        if not question:\n",
    "            return {\"answer\": \"No question provided\"}\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not Path(data_path).exists():\n",
    "            return {\"answer\": f\"Data file not found: {data_path}\"}\n",
    "        \n",
    "        # Create file adapter\n",
    "        file_adapter = LocalFileAdapter(data_path)\n",
    "        \n",
    "        # Build index using ChatIngestor\n",
    "        ingestor = ChatIngestor(\n",
    "            temp_base=\"data\",\n",
    "            faiss_base=\"faiss_index\",\n",
    "            use_session_dirs=True\n",
    "        )\n",
    "        \n",
    "        # Build retriever\n",
    "        ingestor.built_retriver(\n",
    "            uploaded_files=[file_adapter],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        # Get session ID and index path\n",
    "        session_id = ingestor.session_id\n",
    "        index_path = f\"faiss_index/{session_id}\"\n",
    "        \n",
    "        # Create RAG instance and load retriever\n",
    "        rag = ConversationalRAG(session_id=session_id)\n",
    "        rag.load_retriever_from_faiss(\n",
    "            index_path=index_path,\n",
    "            k=k,\n",
    "            index_name=os.getenv(\"FAISS_INDEX_NAME\", \"index\")\n",
    "        )\n",
    "        \n",
    "        # Get answer\n",
    "        answer = rag.invoke(question, chat_history=[])\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cae91ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-11T09:43:41.701569Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:41.702453Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:41.702835Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:43:41.703601Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:43:41.704988Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151341_a7c56d31\", \"temp_dir\": \"data/session_20251111_151341_a7c56d31\", \"faiss_dir\": \"faiss_index/session_20251111_151341_a7c56d31\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:43:41.705499Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151341_a7c56d31/37b433eb.pdf\", \"timestamp\": \"2025-11-11T09:43:41.707985Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:43:42.234540Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:43:42.235767Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:43:42.236235Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151341_a7c56d31\", \"timestamp\": \"2025-11-11T09:43:45.220223Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:43:45.221038Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:45.223954Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:45.224769Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:45.225292Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:43:45.225624Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:43:45.227368Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:43:45.227667Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151341_a7c56d31\", \"timestamp\": \"2025-11-11T09:43:45.229110Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151341_a7c56d31\", \"timestamp\": \"2025-11-11T09:43:45.229358Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:45.230054Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:45.230303Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:43:45.230468Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:43:45.230704Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:43:45.231626Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:43:45.231864Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151341_a7c56d31\", \"timestamp\": \"2025-11-11T09:43:45.233819Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151341_a7c56d31\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151341_a7c56d31\", \"timestamp\": \"2025-11-11T09:43:45.234064Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details..\n",
      "{\"session_id\": \"session_20251111_151341_a7c56d31\", \"user_input\": \"List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\", \"answer_preview\": \"The three advantages of self-attention layers are: lower computational complexity per layer, more computation that can be parallelized, and fewer sequ\", \"timestamp\": \"2025-11-11T09:44:09.908418Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\n",
      "\n",
      "Answer: The three advantages of self-attention layers are: lower computational complexity per layer, more computation that can be parallelized, and fewer sequential operations required.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a sample question\n",
    "test_input = {\"question\": \"List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\"}\n",
    "result = answer_ai_report_question(test_input)\n",
    "print(\"Question:\", test_input[\"question\"])\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421a191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1cd978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-11T09:45:27.605368Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:27.605893Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:27.606197Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:27.606465Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:27.607637Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151527_689f1dcb\", \"temp_dir\": \"data/session_20251111_151527_689f1dcb\", \"faiss_dir\": \"faiss_index/session_20251111_151527_689f1dcb\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:45:27.609187Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151527_689f1dcb/265bc4f2.pdf\", \"timestamp\": \"2025-11-11T09:45:27.611154Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all questions from the dataset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:45:28.010951Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:45:28.012327Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:45:28.012911Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151527_689f1dcb\", \"timestamp\": \"2025-11-11T09:45:30.664301Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:45:30.665035Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:30.666834Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:30.667240Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:30.667625Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:30.668168Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:30.670164Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:45:30.670479Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151527_689f1dcb\", \"timestamp\": \"2025-11-11T09:45:30.672768Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151527_689f1dcb\", \"timestamp\": \"2025-11-11T09:45:30.673113Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:30.673839Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:30.674098Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:30.674296Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:30.674435Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:30.675373Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:45:30.675637Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151527_689f1dcb\", \"timestamp\": \"2025-11-11T09:45:30.677420Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151527_689f1dcb\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151527_689f1dcb\", \"timestamp\": \"2025-11-11T09:45:30.677709Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151527_689f1dcb\", \"user_input\": \"What is the Transformer model introduced in the paper 'Attention Is All You Need'?\", \"answer_preview\": \"The Transformer model architecture uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder is\", \"timestamp\": \"2025-11-11T09:45:43.009670Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:43.012032Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:43.012453Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:43.012952Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:43.013342Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:43.014825Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151543_e1abaaf7\", \"temp_dir\": \"data/session_20251111_151543_e1abaaf7\", \"faiss_dir\": \"faiss_index/session_20251111_151543_e1abaaf7\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:45:43.015346Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151543_e1abaaf7/2ff862d3.pdf\", \"timestamp\": \"2025-11-11T09:45:43.017183Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What is the Transformer model introduced in the paper 'Attention Is All You Need'?\n",
      "A1: The Transformer model architecture uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder is composed of a stack of N = 6 identical layers, each layer has two sub-layers: a multi-head self-attention mechanism, and a simple, position-wise fully connected feed-forward network. The output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:45:43.534725Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:45:43.535984Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:45:43.536468Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151543_e1abaaf7\", \"timestamp\": \"2025-11-11T09:45:46.643261Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:45:46.644041Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:46.647922Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:46.648715Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:46.649162Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:46.649781Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:46.651614Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:45:46.652176Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151543_e1abaaf7\", \"timestamp\": \"2025-11-11T09:45:46.654035Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151543_e1abaaf7\", \"timestamp\": \"2025-11-11T09:45:46.654356Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:46.655027Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:46.655252Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:46.655482Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:46.655652Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:46.656610Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:45:46.656821Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151543_e1abaaf7\", \"timestamp\": \"2025-11-11T09:45:46.658735Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151543_e1abaaf7\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151543_e1abaaf7\", \"timestamp\": \"2025-11-11T09:45:46.658958Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151543_e1abaaf7\", \"user_input\": \"Write the formula for Scaled Dot-Product Attention and briefly explain its components.\", \"answer_preview\": \"The formula for Scaled Dot-Product Attention is: Attention(Q, K, V) = softmax(QKT/\\u221adk)V. In this formula, Q represents the matrix of queries, K repres\", \"timestamp\": \"2025-11-11T09:45:50.695569Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:50.697955Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:50.698307Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:50.698584Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:50.698866Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:50.700280Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151550_8d25138d\", \"temp_dir\": \"data/session_20251111_151550_8d25138d\", \"faiss_dir\": \"faiss_index/session_20251111_151550_8d25138d\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:45:50.701052Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151550_8d25138d/28ab66b9.pdf\", \"timestamp\": \"2025-11-11T09:45:50.703183Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: Write the formula for Scaled Dot-Product Attention and briefly explain its components.\n",
      "A2: The formula for Scaled Dot-Product Attention is: Attention(Q, K, V) = softmax(QKT/√dk)V. In this formula, Q represents the matrix of queries, K represents the matrix of keys, and V represents the matrix of values. The dimension of the keys is represented by dk.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:45:51.211142Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:45:51.212366Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:45:51.212870Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151550_8d25138d\", \"timestamp\": \"2025-11-11T09:45:54.125158Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:45:54.125610Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:54.127015Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:54.127457Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:54.127737Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:54.127975Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:54.129143Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:45:54.129406Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151550_8d25138d\", \"timestamp\": \"2025-11-11T09:45:54.131079Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151550_8d25138d\", \"timestamp\": \"2025-11-11T09:45:54.131283Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:54.131967Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:54.132194Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:45:54.132345Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:45:54.132486Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:45:54.133574Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:45:54.133805Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151550_8d25138d\", \"timestamp\": \"2025-11-11T09:45:54.135501Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151550_8d25138d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151550_8d25138d\", \"timestamp\": \"2025-11-11T09:45:54.135708Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151550_8d25138d\", \"user_input\": \"List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\", \"answer_preview\": \"The three advantages of self-attention layers are: lower computational complexity per layer, more parallelizable computation (lower number of sequenti\", \"timestamp\": \"2025-11-11T09:46:00.980929Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:00.983989Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:00.984472Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:00.984786Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:46:00.985110Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:46:00.986626Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151600_0f47f23c\", \"temp_dir\": \"data/session_20251111_151600_0f47f23c\", \"faiss_dir\": \"faiss_index/session_20251111_151600_0f47f23c\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:46:00.987037Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151600_0f47f23c/8a626919.pdf\", \"timestamp\": \"2025-11-11T09:46:00.988392Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\n",
      "A3: The three advantages of self-attention layers are: lower computational complexity per layer, more parallelizable computation (lower number of sequential operations), and the ability to extrapolate to sequence lengths longer than those encountered during training.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:46:01.365421Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:46:01.366899Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:46:01.367286Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151600_0f47f23c\", \"timestamp\": \"2025-11-11T09:46:04.019058Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:46:04.019807Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:04.022530Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:04.023133Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:04.023480Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:46:04.023873Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:46:04.025384Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:46:04.025738Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151600_0f47f23c\", \"timestamp\": \"2025-11-11T09:46:04.027411Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151600_0f47f23c\", \"timestamp\": \"2025-11-11T09:46:04.027812Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:04.028557Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:04.028868Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:04.029085Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:46:04.029325Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:46:04.030457Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:46:04.030760Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151600_0f47f23c\", \"timestamp\": \"2025-11-11T09:46:04.032553Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151600_0f47f23c\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151600_0f47f23c\", \"timestamp\": \"2025-11-11T09:46:04.032798Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151600_0f47f23c\", \"user_input\": \"What are the equations for positional encoding and why are they important in the Transformer?\", \"answer_preview\": \"The equations for positional encoding are:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\n\\nPositional encodings are a\", \"timestamp\": \"2025-11-11T09:46:12.201088Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:12.203064Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:12.203661Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:12.204009Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:46:12.204352Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:46:12.205511Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151612_36f28eb4\", \"temp_dir\": \"data/session_20251111_151612_36f28eb4\", \"faiss_dir\": \"faiss_index/session_20251111_151612_36f28eb4\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:46:12.205992Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151612_36f28eb4/548d9852.pdf\", \"timestamp\": \"2025-11-11T09:46:12.207474Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: What are the equations for positional encoding and why are they important in the Transformer?\n",
      "A4: The equations for positional encoding are:\n",
      "P E(pos,2i) = sin(pos/100002i/dmodel )\n",
      "P E(pos,2i+1) = cos(pos/100002i/dmodel )\n",
      "\n",
      "Positional encodings are added to the input embeddings to provide information about the position of tokens in the sequence. The model can easily learn to attend by relative positions because, for any fixed offset k, P Epos+k can be represented as a linear function of P Epos.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:46:12.697869Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:46:12.699648Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:46:12.700294Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151612_36f28eb4\", \"timestamp\": \"2025-11-11T09:46:15.694779Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:46:15.695778Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:15.699744Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:15.700626Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:15.701183Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:46:15.701686Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:46:15.703906Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:46:15.704225Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151612_36f28eb4\", \"timestamp\": \"2025-11-11T09:46:15.706475Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151612_36f28eb4\", \"timestamp\": \"2025-11-11T09:46:15.706874Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:15.708314Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:15.708813Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:46:15.709451Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:46:15.709861Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:46:15.711795Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:46:15.712261Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151612_36f28eb4\", \"timestamp\": \"2025-11-11T09:46:15.714257Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151612_36f28eb4\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151612_36f28eb4\", \"timestamp\": \"2025-11-11T09:46:15.714494Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151612_36f28eb4\", \"user_input\": \"Which optimizer and learning rate schedule were used in the Transformer model, and what value was chosen for warmup_steps?\", \"answer_preview\": \"The Adam optimizer was used with \\u03b21 = 0.9, \\u03b22 = 0.98 and \\u03f5 = 10\\u22129. The learning rate was varied over the course of training according to a specific fo\", \"timestamp\": \"2025-11-11T09:46:28.729483Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: Which optimizer and learning rate schedule were used in the Transformer model, and what value was chosen for warmup_steps?\n",
      "A5: The Adam optimizer was used with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. The learning rate was varied over the course of training according to a specific formula. The value chosen for warmup_steps was 4000.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Test with all datasetquestions\n",
    "print(\"Testing all questions from the dataset:\\n\")\n",
    "for i, q in enumerate(inputs, 1):\n",
    "    test_input = {\"question\": q}\n",
    "    result = answer_ai_report_question(test_input)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\"A{i}: {result['answer']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a99d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shantanusingh/Downloads/Multi_doc_chat_proj/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test-llmops_attention_paper_dataset-qa-rag-0c7f5bbe' at:\n",
      "https://smith.langchain.com/o/c1f713d4-59f0-447c-a0af-c045e1a36407/datasets/6fb8b6b2-44b0-40ae-80a3-ae608cec8207/compare?selectedSessions=6f7420bf-6b05-4def-b4ff-40703f52cbd4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]{\"timestamp\": \"2025-11-11T09:47:19.981406Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:19.981768Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:19.982006Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:19.982251Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:19.983503Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151719_6f43682d\", \"temp_dir\": \"data/session_20251111_151719_6f43682d\", \"faiss_dir\": \"faiss_index/session_20251111_151719_6f43682d\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:47:19.983915Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151719_6f43682d/45aa384e.pdf\", \"timestamp\": \"2025-11-11T09:47:19.985588Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:47:20.533075Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:47:20.534299Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:47:20.534705Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151719_6f43682d\", \"timestamp\": \"2025-11-11T09:47:23.717779Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:47:23.718531Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:23.721305Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:23.721762Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:23.722167Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:23.722459Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:23.724724Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:47:23.725094Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151719_6f43682d\", \"timestamp\": \"2025-11-11T09:47:23.727583Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151719_6f43682d\", \"timestamp\": \"2025-11-11T09:47:23.727913Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:23.728577Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:23.728842Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:23.729001Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:23.729147Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:23.730103Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:47:23.730355Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151719_6f43682d\", \"timestamp\": \"2025-11-11T09:47:23.732235Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151719_6f43682d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151719_6f43682d\", \"timestamp\": \"2025-11-11T09:47:23.732489Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151719_6f43682d\", \"user_input\": \"List three advantages of self-attention over recurrent or convolutional layers mentioned in the paper.\", \"answer_preview\": \"The three advantages of self-attention layers are: lower computational complexity per layer, more parallelizable computation (lower number of sequenti\", \"timestamp\": \"2025-11-11T09:47:28.719156Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "1it [00:13, 13.23s/it]{\"timestamp\": \"2025-11-11T09:47:33.213676Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:33.214183Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:33.214622Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:33.215063Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:33.216145Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151733_bab11a28\", \"temp_dir\": \"data/session_20251111_151733_bab11a28\", \"faiss_dir\": \"faiss_index/session_20251111_151733_bab11a28\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:47:33.216684Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151733_bab11a28/ec0ede1a.pdf\", \"timestamp\": \"2025-11-11T09:47:33.218504Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:47:33.795509Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:47:33.796905Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:47:33.797694Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151733_bab11a28\", \"timestamp\": \"2025-11-11T09:47:36.680514Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:47:36.681193Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:36.683956Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:36.684935Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:36.685467Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:36.685964Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:36.687856Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:47:36.688269Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151733_bab11a28\", \"timestamp\": \"2025-11-11T09:47:36.689909Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151733_bab11a28\", \"timestamp\": \"2025-11-11T09:47:36.690340Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:36.691105Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:36.691378Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:36.691642Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:36.691893Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:36.693107Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:47:36.693383Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151733_bab11a28\", \"timestamp\": \"2025-11-11T09:47:36.695312Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151733_bab11a28\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151733_bab11a28\", \"timestamp\": \"2025-11-11T09:47:36.695592Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151733_bab11a28\", \"user_input\": \"Write the formula for Scaled Dot-Product Attention and briefly explain its components.\", \"answer_preview\": \"The formula for Scaled Dot-Product Attention is: Attention(Q, K, V) = softmax(QKT/\\u221adk)V. In this formula, Q represents the matrix of queries, K repres\", \"timestamp\": \"2025-11-11T09:47:40.862349Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2it [00:28, 14.27s/it]{\"timestamp\": \"2025-11-11T09:47:48.210303Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:48.210689Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:48.211008Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:48.211302Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:48.212639Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151748_2519d060\", \"temp_dir\": \"data/session_20251111_151748_2519d060\", \"faiss_dir\": \"faiss_index/session_20251111_151748_2519d060\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:47:48.213146Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151748_2519d060/3ea528d2.pdf\", \"timestamp\": \"2025-11-11T09:47:48.215012Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:47:48.598126Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:47:48.600254Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:47:48.601021Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151748_2519d060\", \"timestamp\": \"2025-11-11T09:47:51.528409Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:47:51.529229Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:51.531342Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:51.531870Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:51.532244Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:51.532565Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:51.534565Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:47:51.534993Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151748_2519d060\", \"timestamp\": \"2025-11-11T09:47:51.537428Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151748_2519d060\", \"timestamp\": \"2025-11-11T09:47:51.537851Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:51.538735Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:51.539002Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:47:51.539212Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:47:51.539363Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:47:51.540433Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:47:51.540670Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151748_2519d060\", \"timestamp\": \"2025-11-11T09:47:51.542454Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151748_2519d060\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151748_2519d060\", \"timestamp\": \"2025-11-11T09:47:51.542676Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151748_2519d060\", \"user_input\": \"What are the equations for positional encoding and why are they important in the Transformer?\", \"answer_preview\": \"The equations for positional encoding are:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\n\\nPositional encodings are a\", \"timestamp\": \"2025-11-11T09:47:59.940055Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "3it [00:43, 14.65s/it]{\"timestamp\": \"2025-11-11T09:48:03.311493Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:03.312063Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:03.312400Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:48:03.312712Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:48:03.314082Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151803_32dbf04d\", \"temp_dir\": \"data/session_20251111_151803_32dbf04d\", \"faiss_dir\": \"faiss_index/session_20251111_151803_32dbf04d\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:48:03.314660Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151803_32dbf04d/fc151a92.pdf\", \"timestamp\": \"2025-11-11T09:48:03.317671Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:48:03.894925Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:48:03.896555Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:48:03.897425Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151803_32dbf04d\", \"timestamp\": \"2025-11-11T09:48:06.887919Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:48:06.889166Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:06.892670Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:06.893531Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:06.894004Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:48:06.894413Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:48:06.895892Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:48:06.896269Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151803_32dbf04d\", \"timestamp\": \"2025-11-11T09:48:06.897919Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151803_32dbf04d\", \"timestamp\": \"2025-11-11T09:48:06.898204Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:06.898945Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:06.899572Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:06.899913Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:48:06.900182Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:48:06.901180Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:48:06.901407Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151803_32dbf04d\", \"timestamp\": \"2025-11-11T09:48:06.904494Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151803_32dbf04d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151803_32dbf04d\", \"timestamp\": \"2025-11-11T09:48:06.905039Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details..\n",
      "{\"session_id\": \"session_20251111_151803_32dbf04d\", \"user_input\": \"Which optimizer and learning rate schedule were used in the Transformer model, and what value was chosen for warmup_steps?\", \"answer_preview\": \"The Adam optimizer was used with \\u03b21 = 0.9, \\u03b22 = 0.98 and \\u03f5 = 10\\u22129. The learning rate was varied over the course of training according to a specific fo\", \"timestamp\": \"2025-11-11T09:48:15.319288Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "4it [00:59, 15.37s/it]{\"timestamp\": \"2025-11-11T09:48:19.794672Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:19.795135Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:19.795504Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:48:19.796101Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:48:19.797976Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251111_151819_9b9aa7ff\", \"temp_dir\": \"data/session_20251111_151819_9b9aa7ff\", \"faiss_dir\": \"faiss_index/session_20251111_151819_9b9aa7ff\", \"sessionized\": true, \"timestamp\": \"2025-11-11T09:48:19.798502Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"attention.pdf\", \"saved_as\": \"data/session_20251111_151819_9b9aa7ff/e8bd80b1.pdf\", \"timestamp\": \"2025-11-11T09:48:19.800582Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 15, \"timestamp\": \"2025-11-11T09:48:20.365655Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 52, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-11T09:48:20.367060Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:48:20.367636Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251111_151819_9b9aa7ff\", \"timestamp\": \"2025-11-11T09:48:23.370875Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-11T09:48:23.371743Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:23.374531Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:23.375106Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:23.375520Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:48:23.375882Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:48:23.377834Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-11-11T09:48:23.378143Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251111_151819_9b9aa7ff\", \"timestamp\": \"2025-11-11T09:48:23.379854Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151819_9b9aa7ff\", \"timestamp\": \"2025-11-11T09:48:23.380182Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:23.381041Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:23.381383Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-11-11T09:48:23.381578Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_a5...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-11T09:48:23.381957Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-11-11T09:48:23.382930Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-11-11T09:48:23.383232Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251111_151819_9b9aa7ff\", \"timestamp\": \"2025-11-11T09:48:23.384994Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251111_151819_9b9aa7ff\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251111_151819_9b9aa7ff\", \"timestamp\": \"2025-11-11T09:48:23.385212Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251111_151819_9b9aa7ff\", \"user_input\": \"What is the Transformer model introduced in the paper 'Attention Is All You Need'?\", \"answer_preview\": \"The Transformer model architecture uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder is\", \"timestamp\": \"2025-11-11T09:48:28.800782Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "5it [01:13, 14.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# Evaluators\n",
    "qa_evaluator = [LangChainStringEvaluator(\"cot_qa\")]\n",
    "dataset_name = \"llmops_attention_paper_dataset\"\n",
    "\n",
    "# Run evaluation using our RAG function\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=qa_evaluator,\n",
    "    experiment_prefix=\"test-llmops_attention_paper_dataset-qa-rag\",\n",
    "    # Experiment metadata\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and Attention Paper\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb739e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
